{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628f01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from libsvm.svmutil import *\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c468c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "X_train = pd.read_csv(\"data/X_train.csv\", header=None).to_numpy()\n",
    "y_train = pd.read_csv(\"data/y_train.csv\", header=None).to_numpy().reshape(-1)\n",
    "X_test  = pd.read_csv(\"data/X_test.csv\", header=None).to_numpy()\n",
    "y_test  = pd.read_csv(\"data/y_test.csv\", header=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40edaa57",
   "metadata": {},
   "source": [
    "# Part1: \n",
    "Use different kernel functions (linear, polynomial, and RBF kernels) and have comparison between their performance.\n",
    "![svm_param](img/svm_param.PNG)\n",
    "reference from https://github.com/cjlin1/libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9bfaa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_type:linear, accuracy: 95.08\n",
      "kernel_type:polynomial, accuracy: 34.68\n",
      "kernel_type:radial basis function, accuracy: 95.32\n"
     ]
    }
   ],
   "source": [
    "kernel_types = {'linear':'-q -t 0',\n",
    "                'polynomial':'-q -t 1',\n",
    "                'radial basis function':'-q -t 2'}\n",
    "\n",
    "for kernel_type in kernel_types:\n",
    "    model = svm_train(y_train, X_train, arg3=kernel_types[kernel_type])\n",
    "    p_labels, p_acc, p_vals = svm_predict(y_test, X_test, model, '-q')\n",
    "    \n",
    "    # p_acc: a tuple including accuracy (for classification), mean-squared error, \n",
    "    # and squared correlation coefficient (for regression).\n",
    "    print(\"kernel_type:{}, accuracy: {:.2f}\".format(kernel_type, p_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842e49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5ca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fa83ca2",
   "metadata": {},
   "source": [
    "# Part2: \n",
    "Please use C-SVC. please do the grid search for finding parameters of the best performing model. For instance, in C-SVC you have a parameter C, and if you use RBF kernel you have another parameter ğ›¾, you can search for a set of (C, ğ›¾) which gives you best performance in cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47650d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(log2c, log2g, X_train, y_train, X_test ,y_test):\n",
    "    best_lc = log2c[0]\n",
    "    best_lg = log2g[0]\n",
    "    best_acc = 0\n",
    "    for lc in log2c:\n",
    "        for lg in log2g:\n",
    "            arg3 = '-q -t 2 -v 3 -c {} -g {}'.format(2.0**lc, 2.0**lg)\n",
    "            acc = svm_train(y_train, X_train, arg3=arg3)\n",
    "            \n",
    "            \n",
    "            if acc > best_acc:\n",
    "                best_lc = lc\n",
    "                best_lg = lg\n",
    "                best_acc = acc\n",
    "    return best_lc, best_lg, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a2ba12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 94.18%\n",
      "Cross Validation Accuracy = 41.56%\n",
      "Cross Validation Accuracy = 21.86%\n",
      "Cross Validation Accuracy = 20.32%\n",
      "Cross Validation Accuracy = 78.9%\n",
      "Cross Validation Accuracy = 54%\n",
      "Cross Validation Accuracy = 96.96%\n",
      "Cross Validation Accuracy = 47.66%\n",
      "Cross Validation Accuracy = 21.68%\n",
      "Cross Validation Accuracy = 20.22%\n",
      "Cross Validation Accuracy = 78.78%\n",
      "Cross Validation Accuracy = 54.06%\n",
      "Cross Validation Accuracy = 97.92%\n",
      "Cross Validation Accuracy = 54.34%\n",
      "Cross Validation Accuracy = 25.32%\n",
      "Cross Validation Accuracy = 20.22%\n",
      "Cross Validation Accuracy = 79.04%\n",
      "Cross Validation Accuracy = 40.98%\n",
      "Cross Validation Accuracy = 98.4%\n",
      "Cross Validation Accuracy = 85%\n",
      "Cross Validation Accuracy = 45.7%\n",
      "Cross Validation Accuracy = 25.08%\n",
      "Cross Validation Accuracy = 20.52%\n",
      "Cross Validation Accuracy = 35%\n",
      "Cross Validation Accuracy = 98.54%\n",
      "Cross Validation Accuracy = 85.24%\n",
      "Cross Validation Accuracy = 44.92%\n",
      "Cross Validation Accuracy = 25.24%\n",
      "Cross Validation Accuracy = 20.9%\n",
      "Cross Validation Accuracy = 35.1%\n",
      "Cross Validation Accuracy = 98.4%\n",
      "Cross Validation Accuracy = 85.04%\n",
      "Cross Validation Accuracy = 44.68%\n",
      "Cross Validation Accuracy = 25.42%\n",
      "Cross Validation Accuracy = 26.98%\n",
      "Cross Validation Accuracy = 35.44%\n",
      "Best set (C, gamma)=(2^3, 2^-5), accuracy:98.54%\n"
     ]
    }
   ],
   "source": [
    "log2c = [-5, -3, -1, 1, 3, 5]\n",
    "log2g = [-5, -3, -1, 1, 3, 5]\n",
    "best_lc, best_lg, best_acc = grid_search(log2c, log2g, X_train, y_train, X_test, y_test)\n",
    "print(\"Best set (C, gamma)=(2^{}, 2^{}), accuracy:{}%\".format(best_lc, best_lg, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49c774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "426a1574",
   "metadata": {},
   "source": [
    "# Part3: \n",
    "Use linear kernel + RBF kernel together (therefore a new kernel function) and compare its performance with respect to others. You would need to find out how to use a user-defined kernel in libsvm.\n",
    "\n",
    "reference from https://stackoverflow.com/questions/7715138/using-precomputed-kernels-with-libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a97f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userDefined_kernel(X, X_, gamma):\n",
    "    kernel_linear = X @ X_.T\n",
    "    kernel_RBF = np.exp(-gamma*cdist(X, X_, 'sqeuclidean'))  # seuclideanï¼šæ¨™æº–åŒ–æ­å¼è·é›¢\n",
    "    kernel = kernel_linear + kernel_RBF\n",
    "    kernel = np.hstack((np.arange(1, len(X)+1).reshape(-1,1), kernel))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e0e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear kernel + RBF kernel accuracy: 95.64%\n"
     ]
    }
   ],
   "source": [
    "K  = userDefined_kernel(X_train, X_train, 2**best_lg)    # best_lg: from part2\n",
    "KK = userDefined_kernel(X_test, X_train, 2**best_lg)     # best_lg: from part2\n",
    "\n",
    "prob  = svm_problem(y_train, K, isKernel=True)\n",
    "param = svm_parameter('-q -t 4')\n",
    "model = svm_train(prob, param)\n",
    "p_label, p_acc, p_vals = svm_predict(y_test, KK, model, '-q')\n",
    "print('linear kernel + RBF kernel accuracy: {:.2f}%'.format(p_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12063f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02723ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecbe3d9d",
   "metadata": {},
   "source": [
    "# Observation\n",
    "Cè¶Šå¤§ï¼Œæ‡²ç½°è¶Šå¤§ï¼Œè¶Šå°‘support vectorsï¼Œè¶Šæ¥è¿‘hard-margin SVMçš„æ¦‚å¿µï¼Œå»å®¹æ˜“overfitting\n",
    "\n",
    "Cè¶Šå°ï¼Œæ‡²ç½°è¶Šå°ï¼Œè¶Šå¤šsupport vectorsï¼Œå¯ä»¥è¿½æ±‚æ›´å¤§çš„margin\n",
    "\n",
    "gammaå¤§ï¼Œè³‡æ–™é»çš„å½±éŸ¿åŠ›ç¯„åœæ¯”è¼ƒè¿‘ï¼Œå°è¶…å¹³é¢ä¾†èªªï¼Œè¿‘é»çš„å½±éŸ¿åŠ›æ¬Šé‡è¼ƒå¤§ï¼Œå®¹æ˜“å‹¾å‹’å‡ºæ“¬åˆè¿‘é»çš„è¶…å¹³é¢ï¼Œä¹Ÿå®¹æ˜“é€ æˆoverfittingã€‚\n",
    "\n",
    "gammaå°ï¼Œè³‡æ–™é»çš„å½±éŸ¿åŠ›ç¯„åœæ¯”è¼ƒé ï¼Œå°è¶…å¹³é¢ä¾†èªªï¼Œè¼ƒé çš„è³‡æ–™é»ä¹Ÿæœ‰å½±éŸ¿åŠ›ï¼Œå› æ­¤èƒ½å‹¾å‹’å‡ºå¹³æ»‘ã€è¿‘ä¼¼ç›´ç·šçš„è¶…å¹³é¢ã€‚\n",
    "\n",
    "reference from https://rpubs.com/skydome20/R-Note14-SVM-SVR\n",
    "\n",
    "è¿™é‡Œé¢å¤§å®¶éœ€è¦æ³¨æ„çš„å°±æ˜¯gammaçš„ç‰©ç†æ„ä¹‰ï¼Œå¤§å®¶æåˆ°å¾ˆå¤šçš„RBFçš„å¹…å®½ï¼Œå®ƒä¼šå½±å“æ¯ä¸ªæ”¯æŒå‘é‡å¯¹åº”çš„é«˜æ–¯çš„ä½œç”¨èŒƒå›´ï¼Œä»è€Œå½±å“æ³›åŒ–æ€§èƒ½ã€‚æˆ‘çš„ç†è§£ï¼šå¦‚æœgammaè®¾çš„å¤ªå¤§ï¼Œæ¨™æº–å·®ä¼šå¾ˆå°ï¼Œå¾ˆå°çš„æ¨™æº–å·®é«˜æ–¯åˆ†å¸ƒé•¿å¾—åˆé«˜åˆç˜¦ï¼Œ ä¼šé€ æˆåªä¼šä½œç”¨äºæ”¯æŒå‘é‡æ ·æœ¬é™„è¿‘ï¼Œå¯¹äºæœªçŸ¥æ ·æœ¬åˆ†ç±»æ•ˆæœå¾ˆå·®ï¼Œå­˜åœ¨è®­ç»ƒå‡†ç¡®ç‡å¯ä»¥å¾ˆé«˜ï¼Œè€Œæµ‹è¯•å‡†ç¡®ç‡ä¸é«˜çš„å¯èƒ½ï¼Œå°±æ˜¯é€šå¸¸è¯´çš„è¿‡è®­ç»ƒï¼›è€Œå¦‚æœè®¾çš„è¿‡å°ï¼Œåˆ™ä¼šé€ æˆå¹³æ»‘æ•ˆåº”å¤ªå¤§ï¼Œæ— æ³•åœ¨è®­ç»ƒé›†ä¸Šå¾—åˆ°ç‰¹åˆ«é«˜çš„å‡†ç¡®ç‡ï¼Œä¹Ÿä¼šå½±å“æµ‹è¯•é›†çš„å‡†ç¡®ç‡ã€‚\n",
    "\n",
    "reference from https://blog.csdn.net/lujiandong1/article/details/46386201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cf390",
   "metadata": {},
   "source": [
    "# Observation\n",
    "å˜—è©¦åŠ å…¥polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c50aa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userDefined_kernel(X, X_, gamma):\n",
    "    kernel_linear = X @ X_.T\n",
    "    kernel_poly = (1 + gamma*(X @ X_.T))**5\n",
    "    kernel_RBF = np.exp(-gamma*cdist(X, X_, 'sqeuclidean'))  # seuclideanï¼šæ¨™æº–åŒ–æ­å¼è·é›¢\n",
    "    kernel = kernel_linear + kernel_RBF + kernel_poly\n",
    "    kernel = np.hstack((np.arange(1, len(X)+1).reshape(-1,1), kernel))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a61dcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear kernel + polynomial kernel +RBF kernel accuracy: 97.88%\n"
     ]
    }
   ],
   "source": [
    "K  = userDefined_kernel(X_train, X_train, 2**best_lg)    # best_lg: from part2\n",
    "KK = userDefined_kernel(X_test, X_train, 2**best_lg)     # best_lg: from part2\n",
    "\n",
    "prob  = svm_problem(y_train, K, isKernel=True)\n",
    "param = svm_parameter('-q -t 4')\n",
    "model = svm_train(prob, param)\n",
    "p_label, p_acc, p_vals = svm_predict(y_test, KK, model, '-q')\n",
    "print('linear kernel + polynomial kernel +RBF kernel accuracy: {:.2f}%'.format(p_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c22f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
