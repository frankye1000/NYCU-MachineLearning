{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628f01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from libsvm.svmutil import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c468c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "X_train = pd.read_csv(\"data/X_train.csv\", header=None).to_numpy()\n",
    "y_train = pd.read_csv(\"data/y_train.csv\", header=None).to_numpy().reshape(-1)\n",
    "X_test  = pd.read_csv(\"data/X_test.csv\", header=None).to_numpy()\n",
    "y_test  = pd.read_csv(\"data/y_test.csv\", header=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40edaa57",
   "metadata": {},
   "source": [
    "# Part1: \n",
    "Use different kernel functions (linear, polynomial, and RBF kernels) and have comparison between their performance.\n",
    "![svm_param](img/svm_param.PNG)\n",
    "reference from https://github.com/cjlin1/libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9bfaa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_type:linear, accuracy: 95.08\n",
      "kernel_type:polynomial, accuracy: 34.68\n",
      "kernel_type:radial basis function, accuracy: 95.32\n"
     ]
    }
   ],
   "source": [
    "kernel_types = {'linear':'-q -t 0',\n",
    "                'polynomial':'-q -t 1',\n",
    "                'radial basis function':'-q -t 2'}\n",
    "\n",
    "for kernel_type in kernel_types:\n",
    "    model = svm_train(y_train, X_train, arg3=kernel_types[kernel_type])\n",
    "    p_labels, p_acc, p_vals = svm_predict(y_test, X_test, model, '-q')\n",
    "    \n",
    "    # p_acc: a tuple including accuracy (for classification), mean-squared error, \n",
    "    # and squared correlation coefficient (for regression).\n",
    "    print(\"kernel_type:{}, accuracy: {:.2f}\".format(kernel_type, p_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842e49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5ca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fa83ca2",
   "metadata": {},
   "source": [
    "# Part2: \n",
    "Please use C-SVC. please do the grid search for finding parameters of the best performing model. For instance, in C-SVC you have a parameter C, and if you use RBF kernel you have another parameter 𝛾, you can search for a set of (C, 𝛾) which gives you best performance in cross-validation. \n",
    "\n",
    "2021/12/02 TA:In part 2, please do grid search also for the kernel functions mentioned in part 1 and find the best parameters for each kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d484494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearKernelGridSearch(log10c, X_train, y_train, X_test ,y_test):\n",
    "    best_lc = log10c[0]\n",
    "    best_acc= 0\n",
    "    for lc in log10c:\n",
    "        arg3 = '-q -t 0 -v 3 -c {}'.format(10.0**lc)\n",
    "        acc = svm_train(y_train, X_train, arg3=arg3)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_lc = lc\n",
    "            best_acc = acc\n",
    "    return best_lc, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859710f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 79.32%\n",
      "Cross Validation Accuracy = 88.32%\n",
      "Cross Validation Accuracy = 95.28%\n",
      "Cross Validation Accuracy = 96.92%\n",
      "Cross Validation Accuracy = 97.18%\n",
      "Cross Validation Accuracy = 96.36%\n",
      "Cross Validation Accuracy = 96.02%\n",
      "Cross Validation Accuracy = 96.2%\n",
      "Cross Validation Accuracy = 96.02%\n",
      "Cross Validation Accuracy = 95.96%\n",
      "Cross Validation Accuracy = 96.16%\n",
      "Best set (C)=(10^-1), accuracy:97.18%\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "log10c = [i for i in range(-5, 6)]  # -5~5\n",
    "best_lc, best_acc = LinearKernelGridSearch(log10c, X_train, y_train, \n",
    "                                           X_test, y_test)\n",
    "print(\"Best set (C)=(10^{}), accuracy:{}%\".format(best_lc, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7453706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolyKernelGridSearch(log10c, log10g, coef0, X_train, y_train, X_test, y_test):\n",
    "    best_lc    = log10c[0]\n",
    "    best_lg    = log10g[0]\n",
    "    best_coef0 = coef0[0] \n",
    "    best_acc   = 0\n",
    "    for lc in log10c:\n",
    "        for lg in log10g:\n",
    "            for r in coef0:\n",
    "                arg3 = '-q -t 1 -v 3 -c {} -g {} -r {}'.format(10.0**lc, 10.0**lg, r)\n",
    "                acc = svm_train(y_train, X_train, arg3=arg3)\n",
    "\n",
    "                if acc > best_acc:\n",
    "                    best_lc    = lc\n",
    "                    best_lg    = lg\n",
    "                    best_coef0 = r\n",
    "                    best_acc   = acc\n",
    "    return best_lc, best_lg, best_coef0, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f30a0d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 82.12%\n",
      "Cross Validation Accuracy = 28.78%\n",
      "Cross Validation Accuracy = 77.06%\n",
      "Cross Validation Accuracy = 84.7%\n",
      "Cross Validation Accuracy = 28.48%\n",
      "Cross Validation Accuracy = 76.02%\n",
      "Cross Validation Accuracy = 92.28%\n",
      "Cross Validation Accuracy = 96.12%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 97.6%\n",
      "Cross Validation Accuracy = 97.3%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 97.22%\n",
      "Cross Validation Accuracy = 97.34%\n",
      "Cross Validation Accuracy = 97.22%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 81.76%\n",
      "Cross Validation Accuracy = 28.72%\n",
      "Cross Validation Accuracy = 77.42%\n",
      "Cross Validation Accuracy = 89.38%\n",
      "Cross Validation Accuracy = 58.8%\n",
      "Cross Validation Accuracy = 94.46%\n",
      "Cross Validation Accuracy = 95.74%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 98.02%\n",
      "Cross Validation Accuracy = 97.22%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.58%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.7%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 97.46%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 92.86%\n",
      "Cross Validation Accuracy = 28.68%\n",
      "Cross Validation Accuracy = 93.22%\n",
      "Cross Validation Accuracy = 83.36%\n",
      "Cross Validation Accuracy = 89.22%\n",
      "Cross Validation Accuracy = 97.2%\n",
      "Cross Validation Accuracy = 95.3%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.96%\n",
      "Cross Validation Accuracy = 97.18%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.52%\n",
      "Cross Validation Accuracy = 97.34%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.26%\n",
      "Cross Validation Accuracy = 96.08%\n",
      "Cross Validation Accuracy = 28.58%\n",
      "Cross Validation Accuracy = 96.32%\n",
      "Cross Validation Accuracy = 79.84%\n",
      "Cross Validation Accuracy = 96.2%\n",
      "Cross Validation Accuracy = 97.74%\n",
      "Cross Validation Accuracy = 94.98%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 98.04%\n",
      "Cross Validation Accuracy = 97.32%\n",
      "Cross Validation Accuracy = 97.66%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.2%\n",
      "Cross Validation Accuracy = 97.34%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 97.34%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 96.8%\n",
      "Cross Validation Accuracy = 58.78%\n",
      "Cross Validation Accuracy = 97%\n",
      "Cross Validation Accuracy = 73.98%\n",
      "Cross Validation Accuracy = 97.58%\n",
      "Cross Validation Accuracy = 97.76%\n",
      "Cross Validation Accuracy = 94.96%\n",
      "Cross Validation Accuracy = 97.26%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 97.22%\n",
      "Cross Validation Accuracy = 97.56%\n",
      "Cross Validation Accuracy = 97.56%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.62%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.26%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 95.54%\n",
      "Cross Validation Accuracy = 89.24%\n",
      "Cross Validation Accuracy = 96.94%\n",
      "Cross Validation Accuracy = 76.92%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.7%\n",
      "Cross Validation Accuracy = 95.08%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.96%\n",
      "Cross Validation Accuracy = 97.2%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.6%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.24%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 97.78%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.08%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.24%\n",
      "Cross Validation Accuracy = 94.18%\n",
      "Cross Validation Accuracy = 96.1%\n",
      "Cross Validation Accuracy = 96.7%\n",
      "Cross Validation Accuracy = 77.64%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 97.66%\n",
      "Cross Validation Accuracy = 95.2%\n",
      "Cross Validation Accuracy = 97.62%\n",
      "Cross Validation Accuracy = 97.92%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 97.46%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.58%\n",
      "Cross Validation Accuracy = 97.78%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Best set (C, gamma, coef0)=(10^0, 10^-1, 1), accuracy:98.04%\n"
     ]
    }
   ],
   "source": [
    "# Polynomial\n",
    "log10c = [i for i in range(-3,4)] #-3~3\n",
    "log10g = [i for i in range(-3,4)]\n",
    "coef0  = [-1, 0, 1]\n",
    "best_lc, best_lg, best_coef0, best_acc = PolyKernelGridSearch(log10c, log10g, coef0, X_train, y_train, X_test, y_test)\n",
    "print(\"Best set (C, gamma, coef0)=(10^{}, 10^{}, {}), accuracy:{}%\".format(best_lc, best_lg, best_coef0, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47650d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBFKernelGridSearch(log10c, log10g, X_train, y_train, X_test ,y_test):\n",
    "    best_lc = log10c[0]\n",
    "    best_lg = log10g[0]\n",
    "    best_acc = 0\n",
    "    for lc in log10c:\n",
    "        for lg in log10g:\n",
    "            arg3 = '-q -t 2 -v 3 -c {} -g {}'.format(10.0**lc, 10.0**lg)\n",
    "            acc = svm_train(y_train, X_train, arg3=arg3)\n",
    "            \n",
    "            \n",
    "            if acc > best_acc:\n",
    "                best_lc = lc\n",
    "                best_lg = lg\n",
    "                best_acc = acc\n",
    "    return best_lc, best_lg, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a2ba12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 80.82%\n",
      "Cross Validation Accuracy = 89.88%\n",
      "Cross Validation Accuracy = 49.26%\n",
      "Cross Validation Accuracy = 20.6%\n",
      "Cross Validation Accuracy = 78.84%\n",
      "Cross Validation Accuracy = 35.7%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 80.8%\n",
      "Cross Validation Accuracy = 91.76%\n",
      "Cross Validation Accuracy = 49.12%\n",
      "Cross Validation Accuracy = 20.6%\n",
      "Cross Validation Accuracy = 78.84%\n",
      "Cross Validation Accuracy = 35.82%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 91.86%\n",
      "Cross Validation Accuracy = 96.2%\n",
      "Cross Validation Accuracy = 54.62%\n",
      "Cross Validation Accuracy = 20.64%\n",
      "Cross Validation Accuracy = 79.08%\n",
      "Cross Validation Accuracy = 35.86%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 96.04%\n",
      "Cross Validation Accuracy = 97.62%\n",
      "Cross Validation Accuracy = 90.98%\n",
      "Cross Validation Accuracy = 30.24%\n",
      "Cross Validation Accuracy = 33.36%\n",
      "Cross Validation Accuracy = 36.02%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 97.16%\n",
      "Cross Validation Accuracy = 98.22%\n",
      "Cross Validation Accuracy = 91.46%\n",
      "Cross Validation Accuracy = 31.5%\n",
      "Cross Validation Accuracy = 27%\n",
      "Cross Validation Accuracy = 36.08%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 96.94%\n",
      "Cross Validation Accuracy = 98.04%\n",
      "Cross Validation Accuracy = 91.56%\n",
      "Cross Validation Accuracy = 32.08%\n",
      "Cross Validation Accuracy = 20.64%\n",
      "Cross Validation Accuracy = 36.06%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 96.94%\n",
      "Cross Validation Accuracy = 98.12%\n",
      "Cross Validation Accuracy = 91.88%\n",
      "Cross Validation Accuracy = 31.44%\n",
      "Cross Validation Accuracy = 20.54%\n",
      "Cross Validation Accuracy = 35.96%\n",
      "Cross Validation Accuracy = 20%\n",
      "Best set (C, gamma)=(10^1, 10^-2), accuracy:98.22%\n"
     ]
    }
   ],
   "source": [
    "# RBF\n",
    "log10c = [i for i in range(-3,4)]\n",
    "log10g = [i for i in range(-3,4)]\n",
    "best_lc, best_lg, best_acc = RBFKernelGridSearch(log10c, log10g, X_train, y_train, X_test, y_test)\n",
    "print(\"Best set (C, gamma)=(10^{}, 10^{}), accuracy:{}%\".format(best_lc, best_lg, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2c72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "426a1574",
   "metadata": {},
   "source": [
    "# Part3: \n",
    "Use linear kernel + RBF kernel together (therefore a new kernel function) and compare its performance with respect to others. You would need to find out how to use a user-defined kernel in libsvm.\n",
    "\n",
    "reference from https://stackoverflow.com/questions/7715138/using-precomputed-kernels-with-libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a97f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userDefined_kernel(X, X_, gamma):\n",
    "    kernel_linear = X @ X_.T\n",
    "    kernel_RBF = np.exp(-gamma*cdist(X, X_, 'sqeuclidean'))  # seuclidean：標準化歐式距離\n",
    "    kernel = kernel_linear + kernel_RBF\n",
    "    kernel = np.hstack((np.arange(1, len(X)+1).reshape(-1,1), kernel))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e0e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear kernel + RBF kernel accuracy: 97.24%\n"
     ]
    }
   ],
   "source": [
    "K  = userDefined_kernel(X_train, X_train, 10**best_lg)    # best_lg: from part2\n",
    "KK = userDefined_kernel(X_test, X_train, 10**best_lg)     # best_lg: from part2\n",
    "\n",
    "prob  = svm_problem(y_train, K, isKernel=True)\n",
    "param = svm_parameter('-q -t 4')\n",
    "model = svm_train(prob, param)\n",
    "p_label, p_acc, p_vals = svm_predict(y_test, KK, model, '-q')\n",
    "print('linear kernel + RBF kernel accuracy: {:.2f}%'.format(p_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12063f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02723ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecbe3d9d",
   "metadata": {},
   "source": [
    "# Observation\n",
    "C越大，懲罰越大，越少support vectors，越接近hard-margin SVM的概念，卻容易overfitting\n",
    "\n",
    "C越小，懲罰越小，越多support vectors，可以追求更大的margin\n",
    "\n",
    "gamma大，資料點的影響力範圍比較近，對超平面來說，近點的影響力權重較大，容易勾勒出擬合近點的超平面，也容易造成overfitting。\n",
    "\n",
    "gamma小，資料點的影響力範圍比較遠，對超平面來說，較遠的資料點也有影響力，因此能勾勒出平滑、近似直線的超平面。\n",
    "\n",
    "reference from https://rpubs.com/skydome20/R-Note14-SVM-SVR\n",
    "\n",
    "这里面大家需要注意的就是gamma的物理意义，大家提到很多的RBF的幅宽，它会影响每个支持向量对应的高斯的作用范围，从而影响泛化性能。我的理解：如果gamma设的太大，標準差会很小，很小的標準差高斯分布长得又高又瘦， 会造成只会作用于支持向量样本附近，对于未知样本分类效果很差，存在训练准确率可以很高，而测试准确率不高的可能，就是通常说的过训练；而如果设的过小，则会造成平滑效应太大，无法在训练集上得到特别高的准确率，也会影响测试集的准确率。\n",
    "\n",
    "reference from https://blog.csdn.net/lujiandong1/article/details/46386201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cf390",
   "metadata": {},
   "source": [
    "# Observation\n",
    "嘗試加入polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c50aa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userDefined_kernel(X, X_, gamma):\n",
    "    kernel_linear = X @ X_.T\n",
    "    kernel_poly = (1 + gamma*(X @ X_.T))**5\n",
    "    kernel_RBF = np.exp(-gamma*cdist(X, X_, 'sqeuclidean'))  # seuclidean：標準化歐式距離\n",
    "    kernel = kernel_linear + kernel_RBF + kernel_poly\n",
    "    kernel = np.hstack((np.arange(1, len(X)+1).reshape(-1,1), kernel))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a61dcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear kernel + polynomial kernel +RBF kernel accuracy: 97.24%\n"
     ]
    }
   ],
   "source": [
    "K  = userDefined_kernel(X_train, X_train, 10**best_lg)    # best_lg: from part2\n",
    "KK = userDefined_kernel(X_test, X_train, 10**best_lg)     # best_lg: from part2\n",
    "\n",
    "prob  = svm_problem(y_train, K, isKernel=True)\n",
    "param = svm_parameter('-q -t 4')\n",
    "model = svm_train(prob, param)\n",
    "p_label, p_acc, p_vals = svm_predict(y_test, KK, model, '-q')\n",
    "print('linear kernel + polynomial kernel +RBF kernel accuracy: {:.2f}%'.format(p_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c22f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
