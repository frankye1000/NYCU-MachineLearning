{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628f01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from libsvm.svmutil import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c468c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "X_train = pd.read_csv(\"data/X_train.csv\", header=None).to_numpy()\n",
    "y_train = pd.read_csv(\"data/y_train.csv\", header=None).to_numpy().reshape(-1)\n",
    "X_test  = pd.read_csv(\"data/X_test.csv\", header=None).to_numpy()\n",
    "y_test  = pd.read_csv(\"data/y_test.csv\", header=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40edaa57",
   "metadata": {},
   "source": [
    "# Part1: \n",
    "Use different kernel functions (linear, polynomial, and RBF kernels) and have comparison between their performance.\n",
    "![svm_param](img/svm_param.PNG)\n",
    "reference from https://github.com/cjlin1/libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9bfaa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_type:linear, accuracy: 95.08\n",
      "kernel_type:polynomial, accuracy: 34.68\n",
      "kernel_type:radial basis function, accuracy: 95.32\n"
     ]
    }
   ],
   "source": [
    "kernel_types = {'linear':'-q -t 0',\n",
    "                'polynomial':'-q -t 1',\n",
    "                'radial basis function':'-q -t 2'}\n",
    "\n",
    "for kernel_type in kernel_types:\n",
    "    model = svm_train(y_train, X_train, arg3=kernel_types[kernel_type])\n",
    "    p_labels, p_acc, p_vals = svm_predict(y_test, X_test, model, '-q')\n",
    "    \n",
    "    # p_acc: a tuple including accuracy (for classification), mean-squared error, \n",
    "    # and squared correlation coefficient (for regression).\n",
    "    print(\"kernel_type:{}, accuracy: {:.2f}\".format(kernel_type, p_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842e49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5ca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fa83ca2",
   "metadata": {},
   "source": [
    "# Part2: \n",
    "Please use C-SVC. please do the grid search for finding parameters of the best performing model. For instance, in C-SVC you have a parameter C, and if you use RBF kernel you have another parameter ğ›¾, you can search for a set of (C, ğ›¾) which gives you best performance in cross-validation. \n",
    "\n",
    "2021/12/02 TA:In part 2, please do grid search also for the kernel functions mentioned in part 1 and find the best parameters for each kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d484494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearKernelGridSearch(log10c, X_train, y_train, X_test ,y_test):\n",
    "    best_lc = log10c[0]\n",
    "    best_acc= 0\n",
    "    for lc in log10c:\n",
    "        arg3 = '-q -t 0 -v 3 -c {}'.format(10.0**lc)\n",
    "        acc = svm_train(y_train, X_train, arg3=arg3)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_lc = lc\n",
    "            best_acc = acc\n",
    "    return best_lc, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859710f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 79.32%\n",
      "Cross Validation Accuracy = 88.32%\n",
      "Cross Validation Accuracy = 95.28%\n",
      "Cross Validation Accuracy = 96.92%\n",
      "Cross Validation Accuracy = 97.18%\n",
      "Cross Validation Accuracy = 96.36%\n",
      "Cross Validation Accuracy = 96.02%\n",
      "Cross Validation Accuracy = 96.2%\n",
      "Cross Validation Accuracy = 96.02%\n",
      "Cross Validation Accuracy = 95.96%\n",
      "Cross Validation Accuracy = 96.16%\n",
      "Best set (C)=(10^-1), accuracy:97.18%\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "log10c = [i for i in range(-5, 6)]  # -5~5\n",
    "best_lc, best_acc = LinearKernelGridSearch(log10c, X_train, y_train, \n",
    "                                           X_test, y_test)\n",
    "print(\"Best set (C)=(10^{}), accuracy:{}%\".format(best_lc, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7453706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolyKernelGridSearch(log10c, log10g, coef0, X_train, y_train, X_test, y_test):\n",
    "    best_lc    = log10c[0]\n",
    "    best_lg    = log10g[0]\n",
    "    best_coef0 = coef0[0] \n",
    "    best_acc   = 0\n",
    "    for lc in log10c:\n",
    "        for lg in log10g:\n",
    "            for r in coef0:\n",
    "                arg3 = '-q -t 1 -v 3 -c {} -g {} -r {}'.format(10.0**lc, 10.0**lg, r)\n",
    "                acc = svm_train(y_train, X_train, arg3=arg3)\n",
    "\n",
    "                if acc > best_acc:\n",
    "                    best_lc    = lc\n",
    "                    best_lg    = lg\n",
    "                    best_coef0 = r\n",
    "                    best_acc   = acc\n",
    "    return best_lc, best_lg, best_coef0, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f30a0d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 82.12%\n",
      "Cross Validation Accuracy = 28.78%\n",
      "Cross Validation Accuracy = 77.06%\n",
      "Cross Validation Accuracy = 84.7%\n",
      "Cross Validation Accuracy = 28.48%\n",
      "Cross Validation Accuracy = 76.02%\n",
      "Cross Validation Accuracy = 92.28%\n",
      "Cross Validation Accuracy = 96.12%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 97.6%\n",
      "Cross Validation Accuracy = 97.3%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 97.22%\n",
      "Cross Validation Accuracy = 97.34%\n",
      "Cross Validation Accuracy = 97.22%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 81.76%\n",
      "Cross Validation Accuracy = 28.72%\n",
      "Cross Validation Accuracy = 77.42%\n",
      "Cross Validation Accuracy = 89.38%\n",
      "Cross Validation Accuracy = 58.8%\n",
      "Cross Validation Accuracy = 94.46%\n",
      "Cross Validation Accuracy = 95.74%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 98.02%\n",
      "Cross Validation Accuracy = 97.22%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.58%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.7%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 97.46%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 92.86%\n",
      "Cross Validation Accuracy = 28.68%\n",
      "Cross Validation Accuracy = 93.22%\n",
      "Cross Validation Accuracy = 83.36%\n",
      "Cross Validation Accuracy = 89.22%\n",
      "Cross Validation Accuracy = 97.2%\n",
      "Cross Validation Accuracy = 95.3%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.96%\n",
      "Cross Validation Accuracy = 97.18%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.52%\n",
      "Cross Validation Accuracy = 97.34%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.26%\n",
      "Cross Validation Accuracy = 96.08%\n",
      "Cross Validation Accuracy = 28.58%\n",
      "Cross Validation Accuracy = 96.32%\n",
      "Cross Validation Accuracy = 79.84%\n",
      "Cross Validation Accuracy = 96.2%\n",
      "Cross Validation Accuracy = 97.74%\n",
      "Cross Validation Accuracy = 94.98%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 98.04%\n",
      "Cross Validation Accuracy = 97.32%\n",
      "Cross Validation Accuracy = 97.66%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.2%\n",
      "Cross Validation Accuracy = 97.34%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 97.34%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 96.8%\n",
      "Cross Validation Accuracy = 58.78%\n",
      "Cross Validation Accuracy = 97%\n",
      "Cross Validation Accuracy = 73.98%\n",
      "Cross Validation Accuracy = 97.58%\n",
      "Cross Validation Accuracy = 97.76%\n",
      "Cross Validation Accuracy = 94.96%\n",
      "Cross Validation Accuracy = 97.26%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 97.22%\n",
      "Cross Validation Accuracy = 97.56%\n",
      "Cross Validation Accuracy = 97.56%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.62%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.26%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 95.54%\n",
      "Cross Validation Accuracy = 89.24%\n",
      "Cross Validation Accuracy = 96.94%\n",
      "Cross Validation Accuracy = 76.92%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.7%\n",
      "Cross Validation Accuracy = 95.08%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.96%\n",
      "Cross Validation Accuracy = 97.2%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.6%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.24%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Cross Validation Accuracy = 97.78%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.08%\n",
      "Cross Validation Accuracy = 97.4%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.24%\n",
      "Cross Validation Accuracy = 94.18%\n",
      "Cross Validation Accuracy = 96.1%\n",
      "Cross Validation Accuracy = 96.7%\n",
      "Cross Validation Accuracy = 77.64%\n",
      "Cross Validation Accuracy = 97.64%\n",
      "Cross Validation Accuracy = 97.66%\n",
      "Cross Validation Accuracy = 95.2%\n",
      "Cross Validation Accuracy = 97.62%\n",
      "Cross Validation Accuracy = 97.92%\n",
      "Cross Validation Accuracy = 97.42%\n",
      "Cross Validation Accuracy = 97.46%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.58%\n",
      "Cross Validation Accuracy = 97.78%\n",
      "Cross Validation Accuracy = 97.44%\n",
      "Cross Validation Accuracy = 97.38%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.48%\n",
      "Cross Validation Accuracy = 97.36%\n",
      "Cross Validation Accuracy = 97.54%\n",
      "Cross Validation Accuracy = 97.5%\n",
      "Best set (C, gamma, coef0)=(10^0, 10^-1, 1), accuracy:98.04%\n"
     ]
    }
   ],
   "source": [
    "# Polynomial\n",
    "log10c = [i for i in range(-3,4)] #-3~3\n",
    "log10g = [i for i in range(-3,4)]\n",
    "coef0  = [-1, 0, 1]\n",
    "best_lc, best_lg, best_coef0, best_acc = PolyKernelGridSearch(log10c, log10g, coef0, X_train, y_train, X_test, y_test)\n",
    "print(\"Best set (C, gamma, coef0)=(10^{}, 10^{}, {}), accuracy:{}%\".format(best_lc, best_lg, best_coef0, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47650d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBFKernelGridSearch(log10c, log10g, X_train, y_train, X_test ,y_test):\n",
    "    best_lc = log10c[0]\n",
    "    best_lg = log10g[0]\n",
    "    best_acc = 0\n",
    "    for lc in log10c:\n",
    "        for lg in log10g:\n",
    "            arg3 = '-q -t 2 -v 3 -c {} -g {}'.format(10.0**lc, 10.0**lg)\n",
    "            acc = svm_train(y_train, X_train, arg3=arg3)\n",
    "            \n",
    "            \n",
    "            if acc > best_acc:\n",
    "                best_lc = lc\n",
    "                best_lg = lg\n",
    "                best_acc = acc\n",
    "    return best_lc, best_lg, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a2ba12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 80.82%\n",
      "Cross Validation Accuracy = 89.88%\n",
      "Cross Validation Accuracy = 49.26%\n",
      "Cross Validation Accuracy = 20.6%\n",
      "Cross Validation Accuracy = 78.84%\n",
      "Cross Validation Accuracy = 35.7%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 80.8%\n",
      "Cross Validation Accuracy = 91.76%\n",
      "Cross Validation Accuracy = 49.12%\n",
      "Cross Validation Accuracy = 20.6%\n",
      "Cross Validation Accuracy = 78.84%\n",
      "Cross Validation Accuracy = 35.82%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 91.86%\n",
      "Cross Validation Accuracy = 96.2%\n",
      "Cross Validation Accuracy = 54.62%\n",
      "Cross Validation Accuracy = 20.64%\n",
      "Cross Validation Accuracy = 79.08%\n",
      "Cross Validation Accuracy = 35.86%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 96.04%\n",
      "Cross Validation Accuracy = 97.62%\n",
      "Cross Validation Accuracy = 90.98%\n",
      "Cross Validation Accuracy = 30.24%\n",
      "Cross Validation Accuracy = 33.36%\n",
      "Cross Validation Accuracy = 36.02%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 97.16%\n",
      "Cross Validation Accuracy = 98.22%\n",
      "Cross Validation Accuracy = 91.46%\n",
      "Cross Validation Accuracy = 31.5%\n",
      "Cross Validation Accuracy = 27%\n",
      "Cross Validation Accuracy = 36.08%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 96.94%\n",
      "Cross Validation Accuracy = 98.04%\n",
      "Cross Validation Accuracy = 91.56%\n",
      "Cross Validation Accuracy = 32.08%\n",
      "Cross Validation Accuracy = 20.64%\n",
      "Cross Validation Accuracy = 36.06%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 96.94%\n",
      "Cross Validation Accuracy = 98.12%\n",
      "Cross Validation Accuracy = 91.88%\n",
      "Cross Validation Accuracy = 31.44%\n",
      "Cross Validation Accuracy = 20.54%\n",
      "Cross Validation Accuracy = 35.96%\n",
      "Cross Validation Accuracy = 20%\n",
      "Best set (C, gamma)=(10^1, 10^-2), accuracy:98.22%\n"
     ]
    }
   ],
   "source": [
    "# RBF\n",
    "log10c = [i for i in range(-3,4)]\n",
    "log10g = [i for i in range(-3,4)]\n",
    "best_lc, best_lg, best_acc = RBFKernelGridSearch(log10c, log10g, X_train, y_train, X_test, y_test)\n",
    "print(\"Best set (C, gamma)=(10^{}, 10^{}), accuracy:{}%\".format(best_lc, best_lg, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2c72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "426a1574",
   "metadata": {},
   "source": [
    "# Part3: \n",
    "Use linear kernel + RBF kernel together (therefore a new kernel function) and compare its performance with respect to others. You would need to find out how to use a user-defined kernel in libsvm.\n",
    "\n",
    "reference from https://stackoverflow.com/questions/7715138/using-precomputed-kernels-with-libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a97f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userDefined_kernel(X, X_, gamma):\n",
    "    kernel_linear = X @ X_.T\n",
    "    kernel_RBF = np.exp(-gamma*cdist(X, X_, 'sqeuclidean'))  # seuclideanï¼šæ¨™æº–åŒ–æ­å¼è·é›¢\n",
    "    kernel = kernel_linear + kernel_RBF\n",
    "    kernel = np.hstack((np.arange(1, len(X)+1).reshape(-1,1), kernel))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e0e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear kernel + RBF kernel accuracy: 97.24%\n"
     ]
    }
   ],
   "source": [
    "K  = userDefined_kernel(X_train, X_train, 10**best_lg)    # best_lg: from part2\n",
    "KK = userDefined_kernel(X_test, X_train, 10**best_lg)     # best_lg: from part2\n",
    "\n",
    "prob  = svm_problem(y_train, K, isKernel=True)\n",
    "param = svm_parameter('-q -t 4')\n",
    "model = svm_train(prob, param)\n",
    "p_label, p_acc, p_vals = svm_predict(y_test, KK, model, '-q')\n",
    "print('linear kernel + RBF kernel accuracy: {:.2f}%'.format(p_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12063f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02723ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecbe3d9d",
   "metadata": {},
   "source": [
    "# Observation\n",
    "Cè¶Šå¤§ï¼Œæ‡²ç½°è¶Šå¤§ï¼Œè¶Šå°‘support vectorsï¼Œè¶Šæ¥è¿‘hard-margin SVMçš„æ¦‚å¿µï¼Œå»å®¹æ˜“overfitting\n",
    "\n",
    "Cè¶Šå°ï¼Œæ‡²ç½°è¶Šå°ï¼Œè¶Šå¤šsupport vectorsï¼Œå¯ä»¥è¿½æ±‚æ›´å¤§çš„margin\n",
    "\n",
    "gammaå¤§ï¼Œè³‡æ–™é»çš„å½±éŸ¿åŠ›ç¯„åœæ¯”è¼ƒè¿‘ï¼Œå°è¶…å¹³é¢ä¾†èªªï¼Œè¿‘é»çš„å½±éŸ¿åŠ›æ¬Šé‡è¼ƒå¤§ï¼Œå®¹æ˜“å‹¾å‹’å‡ºæ“¬åˆè¿‘é»çš„è¶…å¹³é¢ï¼Œä¹Ÿå®¹æ˜“é€ æˆoverfittingã€‚\n",
    "\n",
    "gammaå°ï¼Œè³‡æ–™é»çš„å½±éŸ¿åŠ›ç¯„åœæ¯”è¼ƒé ï¼Œå°è¶…å¹³é¢ä¾†èªªï¼Œè¼ƒé çš„è³‡æ–™é»ä¹Ÿæœ‰å½±éŸ¿åŠ›ï¼Œå› æ­¤èƒ½å‹¾å‹’å‡ºå¹³æ»‘ã€è¿‘ä¼¼ç›´ç·šçš„è¶…å¹³é¢ã€‚\n",
    "\n",
    "reference from https://rpubs.com/skydome20/R-Note14-SVM-SVR\n",
    "\n",
    "è¿™é‡Œé¢å¤§å®¶éœ€è¦æ³¨æ„çš„å°±æ˜¯gammaçš„ç‰©ç†æ„ä¹‰ï¼Œå¤§å®¶æåˆ°å¾ˆå¤šçš„RBFçš„å¹…å®½ï¼Œå®ƒä¼šå½±å“æ¯ä¸ªæ”¯æŒå‘é‡å¯¹åº”çš„é«˜æ–¯çš„ä½œç”¨èŒƒå›´ï¼Œä»è€Œå½±å“æ³›åŒ–æ€§èƒ½ã€‚æˆ‘çš„ç†è§£ï¼šå¦‚æœgammaè®¾çš„å¤ªå¤§ï¼Œæ¨™æº–å·®ä¼šå¾ˆå°ï¼Œå¾ˆå°çš„æ¨™æº–å·®é«˜æ–¯åˆ†å¸ƒé•¿å¾—åˆé«˜åˆç˜¦ï¼Œ ä¼šé€ æˆåªä¼šä½œç”¨äºæ”¯æŒå‘é‡æ ·æœ¬é™„è¿‘ï¼Œå¯¹äºæœªçŸ¥æ ·æœ¬åˆ†ç±»æ•ˆæœå¾ˆå·®ï¼Œå­˜åœ¨è®­ç»ƒå‡†ç¡®ç‡å¯ä»¥å¾ˆé«˜ï¼Œè€Œæµ‹è¯•å‡†ç¡®ç‡ä¸é«˜çš„å¯èƒ½ï¼Œå°±æ˜¯é€šå¸¸è¯´çš„è¿‡è®­ç»ƒï¼›è€Œå¦‚æœè®¾çš„è¿‡å°ï¼Œåˆ™ä¼šé€ æˆå¹³æ»‘æ•ˆåº”å¤ªå¤§ï¼Œæ— æ³•åœ¨è®­ç»ƒé›†ä¸Šå¾—åˆ°ç‰¹åˆ«é«˜çš„å‡†ç¡®ç‡ï¼Œä¹Ÿä¼šå½±å“æµ‹è¯•é›†çš„å‡†ç¡®ç‡ã€‚\n",
    "\n",
    "reference from https://blog.csdn.net/lujiandong1/article/details/46386201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cf390",
   "metadata": {},
   "source": [
    "# Observation\n",
    "å˜—è©¦åŠ å…¥polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c50aa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userDefined_kernel(X, X_, gamma):\n",
    "    kernel_linear = X @ X_.T\n",
    "    kernel_poly = (1 + gamma*(X @ X_.T))**5\n",
    "    kernel_RBF = np.exp(-gamma*cdist(X, X_, 'sqeuclidean'))  # seuclideanï¼šæ¨™æº–åŒ–æ­å¼è·é›¢\n",
    "    kernel = kernel_linear + kernel_RBF + kernel_poly\n",
    "    kernel = np.hstack((np.arange(1, len(X)+1).reshape(-1,1), kernel))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a61dcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear kernel + polynomial kernel +RBF kernel accuracy: 97.24%\n"
     ]
    }
   ],
   "source": [
    "K  = userDefined_kernel(X_train, X_train, 10**best_lg)    # best_lg: from part2\n",
    "KK = userDefined_kernel(X_test, X_train, 10**best_lg)     # best_lg: from part2\n",
    "\n",
    "prob  = svm_problem(y_train, K, isKernel=True)\n",
    "param = svm_parameter('-q -t 4')\n",
    "model = svm_train(prob, param)\n",
    "p_label, p_acc, p_vals = svm_predict(y_test, KK, model, '-q')\n",
    "print('linear kernel + polynomial kernel +RBF kernel accuracy: {:.2f}%'.format(p_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c22f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
