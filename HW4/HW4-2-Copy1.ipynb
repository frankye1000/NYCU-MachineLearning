{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e582d51d",
   "metadata": {},
   "source": [
    "# EM algorithm\n",
    "參考:https://mlbhanuyerra.github.io/2018-01-28-Handwritten-Digits_Mixture-of-Bernoulli-Distributions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1041047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from loadMnist import load_images, load_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c87bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW3讀資料\n",
    "train_data = load_images(\"data/train-images.idx3-ubyte\")\n",
    "true       = load_labels(\"data/train-labels.idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e11b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data to 0/1 矩陣\n",
    "train_data[train_data > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257eb566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a5c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist3 = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf454642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    '''\n",
    "    Function to plot the MNIST data\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=plt.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13274956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli(data, means):\n",
    "    '''To compute the probability of x for each bernouli distribution\n",
    "    data = N X D matrix\n",
    "    means = K X D matrix\n",
    "    prob (result) = N X K matrix \n",
    "    '''\n",
    "    N = len(data)\n",
    "    K = len(means)\n",
    "    #compute prob(x|mean)\n",
    "    # prob[i, k] for ith data point(image), and kth cluster/mixture distribution\n",
    "    prob = np.zeros((N, K))\n",
    "    \n",
    "    for i in range(N):\n",
    "        for k in range(K):\n",
    "            prob[i,k] = np.prod((means[k]**data[i])*((1-means[k])**(1-data[i])))\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3144ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respBernoulli(data, weights, means):\n",
    "    '''To compute responsibilities, or posterior probability p(z|x)\n",
    "    data = N X D matrix\n",
    "    weights = K dimensional vector\n",
    "    means = K X D matrix\n",
    "    prob or resp (result) = N X K matrix \n",
    "    '''\n",
    "    #step 1\n",
    "    # calculate the p(x|means)\n",
    "    prob = bernoulli(data, means)\n",
    "    \n",
    "    #step 2\n",
    "    # calculate the numerator of the resp.s\n",
    "    prob = prob*weights\n",
    "    \n",
    "    #step 3\n",
    "    # calcualte the denominator of the resp.s\n",
    "    row_sums = prob.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # step 4\n",
    "    # calculate the resp.s\n",
    "    try:\n",
    "        prob = prob/row_sums\n",
    "        return prob\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Division by zero occured in reponsibility calculations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c86966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulliMStep(data, resp):\n",
    "    '''Re-estimate the parameters using the current responsibilities\n",
    "    data = N X D matrix\n",
    "    resp = N X K matrix\n",
    "    return revised weights (K vector) and means (K X D matrix)\n",
    "    '''\n",
    "    N = len(data)\n",
    "    D = len(data[0])\n",
    "    K = len(resp[0])\n",
    "    \n",
    "    Nk = np.sum(resp, axis=0)\n",
    "    mus = np.empty((K,D))\n",
    "    \n",
    "    for k in range(K):\n",
    "            mus[k] = np.sum(resp[:,k][:,np.newaxis]*data,axis=0) #sum is over N data points\n",
    "            try:\n",
    "                mus[k] = mus[k]/Nk[k]   \n",
    "            except ZeroDivisionError:\n",
    "                print(\"Division by zero occured in Mixture of Bernoulli Dist M-Step!\")\n",
    "                break           \n",
    "    \n",
    "    return (Nk/N, mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5327375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llBernoulli(data, weights, means):\n",
    "    '''To compute expectation of the loglikelihood of Mixture of Beroullie distributions\n",
    "    Since computing E(LL) requires computing responsibilities, this function does a double-duty\n",
    "    to return responsibilities too\n",
    "    '''\n",
    "    N = len(data)\n",
    "    K = len(means)\n",
    "    \n",
    "    resp = respBernoulli(data, weights, means)\n",
    "    \n",
    "    ll = 0\n",
    "    for i in range(N):\n",
    "        sumK = 0\n",
    "        for k in range(K):\n",
    "            try:\n",
    "                temp1 = ((means[k]**data[i])*((1-means[k])**(1-data[i])))\n",
    "                temp1 = np.log(temp1.clip(min=1e-50))\n",
    "                \n",
    "            except:\n",
    "                print(\"Problem computing log(probability)\")\n",
    "            sumK += resp[i, k]*(np.log(weights[k])+np.sum(temp1))\n",
    "        ll += sumK\n",
    "    \n",
    "    return (ll, resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6351ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixOfBernoulliEM(data, init_weights, init_means, maxiters=1000, relgap=1e-4, verbose=False):\n",
    "    '''EM algo fo Mixture of Bernoulli Distributions'''\n",
    "    N = len(data)\n",
    "    D = len(data[0])\n",
    "    K = len(init_means)\n",
    "    \n",
    "    #initalize\n",
    "    weights = init_weights[:]\n",
    "    means = init_means[:]\n",
    "    ll, resp = llBernoulli(data, weights, means)\n",
    "    ll_old = ll\n",
    "    \n",
    "    for i in range(maxiters):\n",
    "        if verbose and (i % 5 ==0):\n",
    "            print(\"iteration {}:\".format(i))\n",
    "            print(\"   {}:\".format(weights))\n",
    "            print(\"   {:.6}\".format(ll))\n",
    "            \n",
    "        #E Step: calculate resps\n",
    "        #Skip, rolled into log likelihood calc\n",
    "        #For 0th step, done as part of initialization\n",
    "            \n",
    "        #M Step\n",
    "        weights, means = bernoulliMStep(data, resp)\n",
    "        \n",
    "        #convergence check\n",
    "        ll, resp = llBernoulli(data, weights, means)\n",
    "        if np.abs(ll-ll_old)<relgap:\n",
    "            print(\"Relative gap:{:.8} at iternations {}\".format(ll-ll_old, i))\n",
    "            break\n",
    "        else:\n",
    "            ll_old = ll\n",
    "            \n",
    "    return (weights, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f753af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def pickData(digits, N):\n",
    "    sData, sTarget = shuffle(mnist3, true, random_state=30)\n",
    "    returnData = np.array([sData[i] for i in range(len(sData)) if sTarget[i] in digits])\n",
    "    return shuffle(returnData, n_samples=N, random_state=30)\n",
    "\n",
    "def experiments(digits, K, N, iters=50):\n",
    "    '''\n",
    "    Picks N random points of the selected 'digits' from MNIST data set and\n",
    "    fits a model using Mixture of Bernoulli distributions.\n",
    "    And returns the weights and means.\n",
    "    '''\n",
    "    \n",
    "    expData = pickData(digits, N)\n",
    "    \n",
    "    D = len(expData[0])\n",
    "\n",
    "    initWts = np.random.uniform(.25,.75,K)\n",
    "    tot = np.sum(initWts)\n",
    "    initWts = initWts/tot\n",
    "    print(\"initWts\", initWts)\n",
    "    \n",
    "    #initMeans = np.random.rand(10,D)\n",
    "    initMeans = np.full((K, D), 1.0/K)\n",
    "    print(\"initMeans\", initMeans)\n",
    "\n",
    "    return mixOfBernoulliEM(expData, initWts, initMeans, maxiters=iters, relgap=1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initWts [0.15324299 0.17882538 0.35029534 0.31763629]\n",
      "initMeans [[0.25 0.25 0.25 ... 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 ... 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 ... 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 ... 0.25 0.25 0.25]]\n"
     ]
    }
   ],
   "source": [
    "finWeights, finMeans = experiments([1,2,3,7], 4, 5000)\n",
    "[show(finMeans[i].reshape(28,28)) for i in range(len(finMeans))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0b4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
