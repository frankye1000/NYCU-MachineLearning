{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e582d51d",
   "metadata": {},
   "source": [
    "# EM algorithm\n",
    "參考:https://mlbhanuyerra.github.io/2018-01-28-Handwritten-Digits_Mixture-of-Bernoulli-Distributions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1041047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from loadMnist import load_images, load_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c87bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 60000\n",
    "# HW3讀資料\n",
    "data = load_images(\"data/train-images.idx3-ubyte\")[:N]\n",
    "true = load_labels(\"data/train-labels.idx1-ubyte\")[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e11b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data to 0/1 矩陣\n",
    "data[data > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a25beb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init Lambda: \n",
      " [0.13412131 0.0626771  0.11505688 0.11837364 0.13749633 0.06142893\n",
      " 0.13529738 0.08342226 0.05665833 0.09546785]\n",
      "init P: \n",
      " [[0.0136914  0.50442465 0.02623742 ... 0.06754934 0.68955997 0.76303332]\n",
      " [0.88901833 0.23731753 0.14747632 ... 0.47673125 0.57263376 0.04668272]\n",
      " [0.75840194 0.73155086 0.64148766 ... 0.60799022 0.22246316 0.05544319]\n",
      " ...\n",
      " [0.53737863 0.93767736 0.13419727 ... 0.28406708 0.71861264 0.95060504]\n",
      " [0.35890996 0.08639793 0.57564042 ... 0.72286219 0.01067405 0.2073523 ]\n",
      " [0.55691593 0.01495693 0.54079675 ... 0.23901225 0.66898999 0.90917637]]\n"
     ]
    }
   ],
   "source": [
    "# 初始化 L(每個類別出現機率) and P(每個類別 每個pixel的p)\n",
    "# w:(10,1)\n",
    "L = np.random.uniform(.25, .75, 10)\n",
    "tot = np.sum(L)\n",
    "L = L/tot\n",
    "print(\"init Lambda: \\n\", L)\n",
    "\n",
    "P = np.random.rand(10, 784)\n",
    "print(\"init P: \\n\", P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed933d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responsibility(data, L, P):\n",
    "    # 課本(9.48) \n",
    "    W = np.zeros((N,10))\n",
    "    for i in range(N):\n",
    "        for j in range(10):    \n",
    "            W[i, j] = np.prod(data[i] * P[j] + (1 - data[i]) * (1 - P)[j])\n",
    "            \n",
    "    # 課本(9.47)\n",
    "    W = W * L.reshape(1, -1)\n",
    "    # 讓每一列(一張圖)機率在區間[0, 1]\n",
    "    sums = np.sum(W, axis=1).reshape(-1, 1)\n",
    "    sums[sums == 0] = 1\n",
    "    W = W / sums\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "def get_L_new(W):\n",
    "    # 課本(9.60)\n",
    "    # 某次出現class i的機率全部加起來/n(把一行的resp加起來/n)\n",
    "    L = np.sum(W, axis=0)\n",
    "    L = L/N\n",
    "    \n",
    "    return L\n",
    "\n",
    "\n",
    "def get_P_new(data, W):\n",
    "    # 課本(9.59) \n",
    "    # (某次出現class i的機率*pixel=1出現次數)/ 某次出現class i的機率全部加起來\n",
    "    sums = np.sum(W, axis=0)\n",
    "    sums[sums==0] = 1\n",
    "    W = W/sums\n",
    "    P = data.T@W\n",
    "    return P.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28f75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a22104",
   "metadata": {},
   "source": [
    "# EM algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b3fbb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Iteration: 1, Difference: 3210.498170533274\n",
      "No. of Iteration: 2, Difference: 314.6151423200065\n",
      "No. of Iteration: 3, Difference: 122.18440569481548\n",
      "No. of Iteration: 4, Difference: 76.15565478482719\n",
      "No. of Iteration: 5, Difference: 56.70866719599603\n",
      "No. of Iteration: 6, Difference: 39.70606600185123\n",
      "No. of Iteration: 7, Difference: 28.623979455665324\n",
      "No. of Iteration: 8, Difference: 20.478836041137097\n",
      "No. of Iteration: 9, Difference: 19.197215501093254\n",
      "No. of Iteration: 10, Difference: 17.518486855895475\n",
      "No. of Iteration: 11, Difference: 15.312429163639393\n",
      "No. of Iteration: 12, Difference: 13.257700507908417\n",
      "No. of Iteration: 13, Difference: 11.235716207181705\n",
      "No. of Iteration: 14, Difference: 9.786410689436202\n",
      "No. of Iteration: 15, Difference: 8.073349116685428\n",
      "No. of Iteration: 16, Difference: 6.66322019716467\n",
      "No. of Iteration: 17, Difference: 5.808112458157886\n"
     ]
    }
   ],
   "source": [
    "diff = 1000\n",
    "iteration = 0\n",
    "for i in range(1, 100):\n",
    "    # E-step:利用已知的P計算resposibility Wi\n",
    "    W = responsibility(data, L, P)\n",
    "        \n",
    "    # M-step:利用 Estep算出的Wi，推得Wi下的L和P\n",
    "    L_new = get_L_new(W)\n",
    "    P_new = get_P_new(data, W)\n",
    "    \n",
    "    # 自定義difference: 就是L和P的差和 \n",
    "    diff_new = np.sum(np.abs(L - L_new)) + np.sum(np.abs(P - P_new))\n",
    "    print(\"No. of Iteration: {}, Difference: {}\".format(i, diff_new))\n",
    "    \n",
    "    # 自定義收斂條件: difference<1\n",
    "    if abs(diff_new - diff) < 1:\n",
    "        break\n",
    "    else:\n",
    "        L = L_new\n",
    "        P = P_new\n",
    "        diff = diff_new\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac6d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbea1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true, preds):\n",
    "    for c in range(10):\n",
    "        TP, FP, FN, TN = 0, 0, 0, 0\n",
    "        for n in range(N):\n",
    "            if c == true[n]:\n",
    "                if true[n] == preds[n]:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1 \n",
    "            else:\n",
    "                if c == preds[n]:\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "        \n",
    "        confusion_matrix = pd.DataFrame([[TP,FP], [FN, TN]], index=(\"Is number {}\".format(c),\"Isn't number {}\".format(c)),\n",
    "                                        columns=(\"Predict number {}\".format(c), \"Predict number {}\".format(c)))\n",
    "        print(confusion_matrix)\n",
    "        print()\n",
    "        print(\"Sensitivity (Successfully predict number {}): {:.5f}\".format(c, TP/(TP+FP)))\n",
    "        print(\"Specificity (Successfully predict number {}): {:.5f}\".format(c, TN/(FN+TN)))\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        \n",
    "def error_rate(true, preds):\n",
    "    error = 0\n",
    "    for n in range(N):\n",
    "        if true[n] != preds[n]:\n",
    "            error += 1\n",
    "    print(\"Total error rate: {}\".format(error/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc134bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b812e9da",
   "metadata": {},
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b4fef",
   "metadata": {},
   "source": [
    "![title](./group.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5327375e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "貼標class: 4 ,真值數量: {4: 3427, 9: 3118, 2: 91, 7: 2646, 3: 280, 8: 291, 5: 326, 0: 9, 1: 7, 6: 13}\n",
      "貼標class: 2 ,真值數量: {3: 1187, 2: 1951, 1: 39, 5: 537, 8: 619, 6: 77, 0: 102, 9: 26, 7: 19, 4: 5}\n",
      "貼標class: 1 ,真值數量: {1: 3545, 4: 5, 6: 8, 8: 40, 3: 5, 7: 12, 2: 2, 9: 4, 5: 1}\n",
      "貼標class: 8 ,真值數量: {4: 1467, 5: 2481, 7: 1335, 8: 2627, 9: 1007, 0: 434, 3: 437, 1: 798, 2: 259, 6: 178}\n",
      "貼標class: 6 ,真值數量: {2: 3265, 6: 5362, 1: 49, 4: 339, 0: 151, 5: 164, 9: 26, 3: 243, 7: 13, 8: 60}\n",
      "貼標class: 0 ,真值數量: {0: 4761, 5: 331, 6: 55, 3: 92, 2: 125, 4: 18, 9: 42, 8: 94, 7: 17}\n",
      "貼標class: 1 ,真值數量: {1: 2295, 9: 1640, 4: 580, 7: 2216, 3: 356, 5: 158, 8: 554, 2: 64, 6: 138, 0: 17}\n",
      "貼標class: 8 ,真值數量: {8: 1}\n",
      "貼標class: 3 ,真值數量: {5: 1423, 3: 3531, 8: 1565, 9: 86, 6: 87, 0: 449, 2: 201, 1: 9, 7: 7, 4: 1}\n"
     ]
    }
   ],
   "source": [
    "# groups: 因為是非監督式學習，所以你得到的是群(G0,G1,...,G9) \n",
    "groups = np.argmax(W, axis=1)\n",
    "\n",
    "# 找出每個群對應的\"類別\"字典\n",
    "group2class_dict = {}\n",
    "for c in range(10):\n",
    "    indexs = np.where(groups==c)[0]       # 首先找出Gi群的index\n",
    "    if len(indexs)==0:                    # !這邊有個問題!: 常常只有八個群(或更少)，所以可能有群沒有index，直接跳過\n",
    "        continue          \n",
    "    \n",
    "    temp = {}\n",
    "    for i in indexs:                      # 用index找出Gi群裡面最多的真值當作，預測類別\n",
    "        if true[i] in temp:\n",
    "            temp[true[i]] += 1\n",
    "        else:\n",
    "            temp[true[i]] = 1\n",
    "    classs = max(temp, key=temp.get)\n",
    "    print(\"貼標class:\",classs, \",真值數量:\", temp)\n",
    "    group2class_dict[c] = classs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8bb7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將群貼上類別標籤=preds\n",
    "preds = np.zeros((60000))\n",
    "for i in range(N):\n",
    "    preds[i] = group2class_dict[groups[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d003aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Predict number 0  Predict number 0\n",
      "Is number 0                 4761              1162\n",
      "Isn't number 0               774             53303\n",
      "\n",
      "Sensitivity (Successfully predict number 0): 0.80382\n",
      "Specificity (Successfully predict number 0): 0.98569\n",
      "------------------------------------------------------------\n",
      "                Predict number 1  Predict number 1\n",
      "Is number 1                 5840               902\n",
      "Isn't number 1              5800             47458\n",
      "\n",
      "Sensitivity (Successfully predict number 1): 0.86621\n",
      "Specificity (Successfully predict number 1): 0.89110\n",
      "------------------------------------------------------------\n",
      "                Predict number 2  Predict number 2\n",
      "Is number 2                 1951              4007\n",
      "Isn't number 2              2611             51431\n",
      "\n",
      "Sensitivity (Successfully predict number 2): 0.32746\n",
      "Specificity (Successfully predict number 2): 0.95169\n",
      "------------------------------------------------------------\n",
      "                Predict number 3  Predict number 3\n",
      "Is number 3                 3531              2600\n",
      "Isn't number 3              3828             50041\n",
      "\n",
      "Sensitivity (Successfully predict number 3): 0.57593\n",
      "Specificity (Successfully predict number 3): 0.92894\n",
      "------------------------------------------------------------\n",
      "                Predict number 4  Predict number 4\n",
      "Is number 4                 3427              2415\n",
      "Isn't number 4              6781             47377\n",
      "\n",
      "Sensitivity (Successfully predict number 4): 0.58661\n",
      "Specificity (Successfully predict number 4): 0.87479\n",
      "------------------------------------------------------------\n",
      "                Predict number 5  Predict number 5\n",
      "Is number 5                    0              5421\n",
      "Isn't number 5                 0             54579\n",
      "\n",
      "Sensitivity (Successfully predict number 5): 0.00000\n",
      "Specificity (Successfully predict number 5): 1.00000\n",
      "------------------------------------------------------------\n",
      "                Predict number 6  Predict number 6\n",
      "Is number 6                 5362               556\n",
      "Isn't number 6              4310             49772\n",
      "\n",
      "Sensitivity (Successfully predict number 6): 0.90605\n",
      "Specificity (Successfully predict number 6): 0.92031\n",
      "------------------------------------------------------------\n",
      "                Predict number 7  Predict number 7\n",
      "Is number 7                    0              6265\n",
      "Isn't number 7                 0             53735\n",
      "\n",
      "Sensitivity (Successfully predict number 7): 0.00000\n",
      "Specificity (Successfully predict number 7): 1.00000\n",
      "------------------------------------------------------------\n",
      "                Predict number 8  Predict number 8\n",
      "Is number 8                 2628              3223\n",
      "Isn't number 8              8396             45753\n",
      "\n",
      "Sensitivity (Successfully predict number 8): 0.44915\n",
      "Specificity (Successfully predict number 8): 0.84495\n",
      "------------------------------------------------------------\n",
      "                Predict number 9  Predict number 9\n",
      "Is number 9                    0              5949\n",
      "Isn't number 9                 0             54051\n",
      "\n",
      "Sensitivity (Successfully predict number 9): 0.00000\n",
      "Specificity (Successfully predict number 9): 1.00000\n",
      "------------------------------------------------------------\n",
      "Total iteration to converge: 16\n",
      "Total error rate: 0.5416666666666666\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(true, preds)     # 會有兩個類別混淆矩陣很怪\n",
    "print(\"Total iteration to converge: {}\".format(iteration))\n",
    "error_rate(true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137388a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2cd127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(P, threshold):\n",
    "    Pattern = np.asarray(P > threshold, dtype='uint8')\n",
    "    for g in group2class_dict:\n",
    "        print('class {}:'.format(group2class_dict[g]))\n",
    "        \n",
    "        temp = Pattern[g]\n",
    "        for i in range(len(temp)):\n",
    "            if i != 0 and i % 28 == 0:\n",
    "                print()\n",
    "            print(temp[i], end=\"\")\n",
    "        print()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ac6faf7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 4:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000001111100111000000000\n",
      "0000000011111000111100000000\n",
      "0000000011100000011100000000\n",
      "0000000011100000011100000000\n",
      "0000000011000000011100000000\n",
      "0000000011000000111100000000\n",
      "0000000011000001111100000000\n",
      "0000000001100011111100000000\n",
      "0000000000000011111000000000\n",
      "0000000000000001111000000000\n",
      "0000000000000001111000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000001100000000000\n",
      "0000000000000001100000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 2:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000001111111100000000000\n",
      "0000000011111111110000000000\n",
      "0000000011111111110000000000\n",
      "0000000011000000110000000000\n",
      "0000000000000000110000000000\n",
      "0000000000000000110000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000111110000000000\n",
      "0000000000000111110000000000\n",
      "0000000000000111000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000010000000\n",
      "0000000000100000000111000000\n",
      "0000000001111000011111000000\n",
      "0000000001111111111111000000\n",
      "0000000000111111111100000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 1:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000110000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000001110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111000000000000\n",
      "0000000000001111000000000000\n",
      "0000000000001111000000000000\n",
      "0000000000001110000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000011100000000000000\n",
      "0000000000011100000000000000\n",
      "0000000000011100000000000000\n",
      "0000000000011000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 8:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000011111111000000\n",
      "0000000000001111111111000000\n",
      "0000000000011110001110000000\n",
      "0000000000011100001110000000\n",
      "0000000000011000001100000000\n",
      "0000000000110000011000000000\n",
      "0000000000011001110000000000\n",
      "0000000000011111110000000000\n",
      "0000000000011111110000000000\n",
      "0000000000001111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000001111000000000000\n",
      "0000000000111110000000000000\n",
      "0000000001111110000000000000\n",
      "0000000001111100000000000000\n",
      "0000000001111000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 6:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000111000000000000\n",
      "0000000000000100000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000111100000000\n",
      "0000000000100011111100000000\n",
      "0000000001111111111100000000\n",
      "0000000011111111111100000000\n",
      "0000000011111111111110000000\n",
      "0000000011111111111110000000\n",
      "0000000011111111111100000000\n",
      "0000000001111111111000000000\n",
      "0000000000111111000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 0:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000011111000000000\n",
      "0000000000001111111100000000\n",
      "0000000000011111111110000000\n",
      "0000000000111111111111000000\n",
      "0000000001111100000111000000\n",
      "0000000011111000000011100000\n",
      "0000000011110000000011100000\n",
      "0000000111100000000011100000\n",
      "0000000111100000000011100000\n",
      "0000001111000000000011100000\n",
      "0000001110000000000011100000\n",
      "0000001110000000000111100000\n",
      "0000001110000000000111000000\n",
      "0000001110000000001111000000\n",
      "0000001111000000011110000000\n",
      "0000001111110011111100000000\n",
      "0000000111111111111000000000\n",
      "0000000011111111100000000000\n",
      "0000000001111110000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 1:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000001111100000000000\n",
      "0000000000001111100000000000\n",
      "0000000000001111100000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000100000000000\n",
      "0000000000000001100000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111000000000000\n",
      "0000000000000111000000000000\n",
      "0000000000000111000000000000\n",
      "0000000000000110000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 8:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000111111111110000\n",
      "0000000000001111111111111000\n",
      "0000000000011111111111111100\n",
      "0000000000011110000000011100\n",
      "0000000000011100000000001100\n",
      "0000000000011100000000000000\n",
      "0000000000011100000001110000\n",
      "0000000000011100011111110000\n",
      "0000000000011101111111100000\n",
      "0000000000011111111100000000\n",
      "0000000001111111100000000000\n",
      "0000000111111110000000000000\n",
      "0000001111111111000000000000\n",
      "0000001110000111000000000000\n",
      "0000001110000011100000000000\n",
      "0000001110000011100000000000\n",
      "0000001111100011000000000000\n",
      "0000000111110011000000000000\n",
      "0000000011111111000000000000\n",
      "0000000011111111000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 3:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000001111111000000000\n",
      "0000000000111111111000000000\n",
      "0000000000111111111100000000\n",
      "0000000000111000011000000000\n",
      "0000000000000000011000000000\n",
      "0000000000000000010000000000\n",
      "0000000000001111110000000000\n",
      "0000000000011111110000000000\n",
      "0000000000111111110000000000\n",
      "0000000000011111111000000000\n",
      "0000000000000000111000000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000111100000000\n",
      "0000000000000000111000000000\n",
      "0000000001111111111000000000\n",
      "0000000011111111110000000000\n",
      "0000000001111111100000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "plot(P, threshold=0.65)    \n",
    "# 改進與感想\n",
    "# 1. 第二多的類別也許才是最佳代表分類 \n",
    "# 2. threshold大小 顯示類別的關鍵pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c659cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
