{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e582d51d",
   "metadata": {},
   "source": [
    "# EM algorithm\n",
    "參考:https://mlbhanuyerra.github.io/2018-01-28-Handwritten-Digits_Mixture-of-Bernoulli-Distributions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1041047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from loadMnist import load_images, load_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c87bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 60000\n",
    "# HW3讀資料\n",
    "data = load_images(\"data/train-images.idx3-ubyte\")[:N]\n",
    "true = load_labels(\"data/train-labels.idx1-ubyte\")[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e11b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data to 0/1 矩陣\n",
    "data[data > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a25beb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init Lambda: \n",
      " [0.10685176 0.12676213 0.0915706  0.11883933 0.07130692 0.0814007\n",
      " 0.08120382 0.10652006 0.14951053 0.06603413]\n",
      "init P: \n",
      " [[0.229566   0.12182178 0.09241054 ... 0.75741331 0.81600426 0.28669333]\n",
      " [0.29121682 0.67051234 0.42958692 ... 0.68763728 0.42670072 0.42067238]\n",
      " [0.72274536 0.61870434 0.14521331 ... 0.17204987 0.73618818 0.58009875]\n",
      " ...\n",
      " [0.27528253 0.62781116 0.49006376 ... 0.645893   0.82445003 0.98585206]\n",
      " [0.27335035 0.68253712 0.75568175 ... 0.87254517 0.38799735 0.07083456]\n",
      " [0.98363703 0.24769425 0.97446195 ... 0.6039563  0.32485887 0.7722092 ]]\n"
     ]
    }
   ],
   "source": [
    "# 初始化 L(每個類別出現機率) and P(每個類別 每個pixel的p)\n",
    "# w:(10,1)\n",
    "L = np.random.uniform(.25, .75, 10)\n",
    "tot = np.sum(L)\n",
    "L = L/tot\n",
    "print(\"init Lambda: \\n\", L)\n",
    "\n",
    "P = np.random.rand(10, 784)\n",
    "print(\"init P: \\n\", P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed933d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responsibility(data, L, P):\n",
    "    # 課本(9.48) \n",
    "    W = np.zeros((N,10))\n",
    "    for i in range(N):\n",
    "        for j in range(10):    \n",
    "            W[i, j] = np.prod(data[i] * P[j] + (1 - data[i]) * (1 - P)[j])\n",
    "            \n",
    "    # 課本(9.47)\n",
    "    W = W * L.reshape(1, -1)\n",
    "    # 讓每一列(一張圖)機率在區間[0, 1]\n",
    "    sums = np.sum(W, axis=1).reshape(-1, 1)\n",
    "    sums[sums == 0] = 1\n",
    "    W = W / sums\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "def get_L_new(W):\n",
    "    # 課本(9.60)\n",
    "    # 某次出現class i的機率全部加起來/n(把一行的resp加起來/n)\n",
    "    L = np.sum(W, axis=0)\n",
    "    L = L/N\n",
    "    \n",
    "    return L\n",
    "\n",
    "\n",
    "def get_P_new(data, W):\n",
    "    # 課本(9.59) \n",
    "    # (某次出現class i的機率*pixel=1出現次數)/ 某次出現class i的機率全部加起來\n",
    "    sums = np.sum(W, axis=0)\n",
    "    sums[sums==0] = 1\n",
    "    W = W/sums\n",
    "    P = data.T@W\n",
    "    return P.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28f75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a22104",
   "metadata": {},
   "source": [
    "# EM algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b3fbb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Iteration: 1, Difference: 3194.62177908525\n",
      "No. of Iteration: 2, Difference: 220.6520511136953\n",
      "No. of Iteration: 3, Difference: 130.65746408435862\n",
      "No. of Iteration: 4, Difference: 86.23840756087189\n",
      "No. of Iteration: 5, Difference: 75.56648463965796\n",
      "No. of Iteration: 6, Difference: 52.369241213692376\n",
      "No. of Iteration: 7, Difference: 36.16076425620772\n",
      "No. of Iteration: 8, Difference: 24.643671220066498\n",
      "No. of Iteration: 9, Difference: 15.514135406609972\n",
      "No. of Iteration: 10, Difference: 9.275618501863539\n",
      "No. of Iteration: 11, Difference: 5.804495350772368\n",
      "No. of Iteration: 12, Difference: 4.314068533290799\n",
      "No. of Iteration: 13, Difference: 3.389790388957467\n"
     ]
    }
   ],
   "source": [
    "diff = 1000\n",
    "iteration = 0\n",
    "for i in range(1, 100):\n",
    "    # E-step:利用已知的P計算resposibility Wi\n",
    "    W = responsibility(data, L, P)\n",
    "        \n",
    "    # M-step:利用 Estep算出的Wi，推得Wi下的L和P\n",
    "    L_new = get_L_new(W)\n",
    "    P_new = get_P_new(data, W)\n",
    "    \n",
    "    # 自定義difference: 就是L和P的差和 \n",
    "    diff_new = np.sum(np.abs(L - L_new)) + np.sum(np.abs(P - P_new))\n",
    "    print(\"No. of Iteration: {}, Difference: {}\".format(i, diff_new))\n",
    "    \n",
    "    # 自定義收斂條件: difference<1\n",
    "    if abs(diff_new - diff) < 1:\n",
    "        break\n",
    "    else:\n",
    "        L = L_new\n",
    "        P = P_new\n",
    "        diff = diff_new\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac6d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbea1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true, preds):\n",
    "    for c in range(10):\n",
    "        TP, FP, FN, TN = 0, 0, 0, 0\n",
    "        for n in range(N):\n",
    "            if c == true[n]:\n",
    "                if true[n] == preds[n]:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1 \n",
    "            else:\n",
    "                if c == preds[n]:\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "        \n",
    "        confusion_matrix = pd.DataFrame([[TP,FP], [FN, TN]], index=(\"Is number {}\".format(c),\"Isn't number {}\".format(c)),\n",
    "                                        columns=(\"Predict number {}\".format(c), \"Predict number {}\".format(c)))\n",
    "        print(confusion_matrix)\n",
    "        print()\n",
    "        print(\"Sensitivity (Successfully predict number {}): {:.5f}\".format(c, TP/(TP+FP)))\n",
    "        print(\"Specificity (Successfully predict number {}): {:.5f}\".format(c, TN/(FN+TN)))\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        \n",
    "def error_rate(true, preds):\n",
    "    error = 0\n",
    "    for n in range(N):\n",
    "        if true[n] != preds[n]:\n",
    "            error += 1\n",
    "    print(\"Total error rate: {}\".format(error/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc134bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b812e9da",
   "metadata": {},
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b4fef",
   "metadata": {},
   "source": [
    "![title](./group.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5327375e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "貼標class: 1 ,真值數量: {1: 6222, 7: 153, 5: 45, 8: 296, 2: 114, 6: 258, 3: 205, 4: 49, 9: 72, 0: 3}\n",
      "貼標class: 7 ,真值數量: {9: 2323, 4: 1195, 7: 2481, 3: 222, 5: 140, 8: 213, 2: 22, 1: 56, 6: 12, 0: 4}\n",
      "貼標class: 4 ,真值數量: {4: 2409, 7: 585, 9: 1482, 3: 85, 8: 101, 5: 156, 2: 117, 6: 37, 0: 21, 1: 8}\n",
      "貼標class: 6 ,真值數量: {2: 3987, 6: 5152, 1: 62, 7: 67, 4: 235, 0: 138, 5: 162, 9: 26, 8: 69, 3: 270}\n",
      "貼標class: 7 ,真值數量: {4: 1654, 7: 2811, 9: 1808, 2: 11, 3: 32, 8: 235, 5: 155, 1: 6, 6: 1}\n",
      "貼標class: 8 ,真值數量: {8: 1}\n",
      "貼標class: 0 ,真值數量: {0: 4691, 5: 127, 3: 57, 6: 53, 9: 28, 8: 67, 7: 13, 2: 98, 4: 8}\n",
      "貼標class: 8 ,真值數量: {3: 1158, 5: 2768, 8: 3029, 0: 804, 4: 290, 6: 331, 2: 473, 1: 355, 9: 91, 7: 85}\n",
      "貼標class: 3 ,真值數量: {5: 1868, 3: 4102, 2: 1136, 9: 119, 8: 1840, 0: 262, 1: 33, 7: 70, 6: 74, 4: 2}\n"
     ]
    }
   ],
   "source": [
    "# groups: 因為是非監督式學習，所以你得到的是群(G0,G1,...,G9) \n",
    "groups = np.argmax(W, axis=1)\n",
    "\n",
    "# 找出每個群對應的\"類別\"字典\n",
    "group2class_dict = {}\n",
    "for c in range(10):\n",
    "    indexs = np.where(groups==c)[0]       # 首先找出Gi群的index\n",
    "    if len(indexs)==0:                    # !這邊有個問題!: 常常只有八個群(或更少)，所以可能有群沒有index，直接跳過\n",
    "        continue          \n",
    "    \n",
    "    temp = {}\n",
    "    for i in indexs:                      # 用index找出Gi群裡面最多的真值當作，預測類別\n",
    "        if true[i] in temp:\n",
    "            temp[true[i]] += 1\n",
    "        else:\n",
    "            temp[true[i]] = 1\n",
    "    classs = max(temp, key=temp.get)\n",
    "    print(\"貼標class:\",classs, \",真值數量:\", temp)\n",
    "    group2class_dict[c] = classs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8bb7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將群貼上類別標籤=preds\n",
    "preds = np.zeros((60000))\n",
    "for i in range(N):\n",
    "    preds[i] = group2class_dict[groups[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d003aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Predict number 0  Predict number 0\n",
      "Is number 0                 4691              1232\n",
      "Isn't number 0               451             53626\n",
      "\n",
      "Sensitivity (Successfully predict number 0): 0.79200\n",
      "Specificity (Successfully predict number 0): 0.99166\n",
      "------------------------------------------------------------\n",
      "                Predict number 1  Predict number 1\n",
      "Is number 1                 6222               520\n",
      "Isn't number 1              1195             52063\n",
      "\n",
      "Sensitivity (Successfully predict number 1): 0.92287\n",
      "Specificity (Successfully predict number 1): 0.97756\n",
      "------------------------------------------------------------\n",
      "                Predict number 2  Predict number 2\n",
      "Is number 2                    0              5958\n",
      "Isn't number 2                 0             54042\n",
      "\n",
      "Sensitivity (Successfully predict number 2): 0.00000\n",
      "Specificity (Successfully predict number 2): 1.00000\n",
      "------------------------------------------------------------\n",
      "                Predict number 3  Predict number 3\n",
      "Is number 3                 4102              2029\n",
      "Isn't number 3              5404             48465\n",
      "\n",
      "Sensitivity (Successfully predict number 3): 0.66906\n",
      "Specificity (Successfully predict number 3): 0.89968\n",
      "------------------------------------------------------------\n",
      "                Predict number 4  Predict number 4\n",
      "Is number 4                 2409              3433\n",
      "Isn't number 4              2592             51566\n",
      "\n",
      "Sensitivity (Successfully predict number 4): 0.41236\n",
      "Specificity (Successfully predict number 4): 0.95214\n",
      "------------------------------------------------------------\n",
      "                Predict number 5  Predict number 5\n",
      "Is number 5                    0              5421\n",
      "Isn't number 5                 0             54579\n",
      "\n",
      "Sensitivity (Successfully predict number 5): 0.00000\n",
      "Specificity (Successfully predict number 5): 1.00000\n",
      "------------------------------------------------------------\n",
      "                Predict number 6  Predict number 6\n",
      "Is number 6                 5152               766\n",
      "Isn't number 6              5016             49066\n",
      "\n",
      "Sensitivity (Successfully predict number 6): 0.87056\n",
      "Specificity (Successfully predict number 6): 0.90725\n",
      "------------------------------------------------------------\n",
      "                Predict number 7  Predict number 7\n",
      "Is number 7                 5292               973\n",
      "Isn't number 7              8089             45646\n",
      "\n",
      "Sensitivity (Successfully predict number 7): 0.84469\n",
      "Specificity (Successfully predict number 7): 0.84946\n",
      "------------------------------------------------------------\n",
      "                Predict number 8  Predict number 8\n",
      "Is number 8                 3030              2821\n",
      "Isn't number 8              6355             47794\n",
      "\n",
      "Sensitivity (Successfully predict number 8): 0.51786\n",
      "Specificity (Successfully predict number 8): 0.88264\n",
      "------------------------------------------------------------\n",
      "                Predict number 9  Predict number 9\n",
      "Is number 9                    0              5949\n",
      "Isn't number 9                 0             54051\n",
      "\n",
      "Sensitivity (Successfully predict number 9): 0.00000\n",
      "Specificity (Successfully predict number 9): 1.00000\n",
      "------------------------------------------------------------\n",
      "Total iteration to converge: 12\n",
      "Total error rate: 0.4850333333333333\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(true, preds)     # 會有兩個類別混淆矩陣很怪\n",
    "print(\"Total iteration to converge: {}\".format(iteration))\n",
    "error_rate(true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137388a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2cd127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(P, threshold):\n",
    "    Pattern = np.asarray(P > threshold, dtype='uint8')\n",
    "    for g in group2class_dict:\n",
    "        print('class {}:'.format(group2class_dict[g]))\n",
    "        \n",
    "        temp = Pattern[g]\n",
    "        for i in range(len(temp)):\n",
    "            if i != 0 and i % 28 == 0:\n",
    "                print()\n",
    "            print(temp[i], end=\"\")\n",
    "        print()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ac6faf7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 1:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000001100000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000001111100000000000\n",
      "0000000000001111000000000000\n",
      "0000000000001111000000000000\n",
      "0000000000001111000000000000\n",
      "0000000000001111000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 7:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000011111110000000000\n",
      "0000000001111111111000000000\n",
      "0000000001111111111100000000\n",
      "0000000011111001111100000000\n",
      "0000000001110000111000000000\n",
      "0000000001100001111000000000\n",
      "0000000001100001111000000000\n",
      "0000000001100011111000000000\n",
      "0000000000000011111000000000\n",
      "0000000000000011111000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011110000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000111100000000000\n",
      "0000000000000011000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 4:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000110000000000000000\n",
      "0000000011111000111100000000\n",
      "0000000111110000111100000000\n",
      "0000000111100000011100000000\n",
      "0000000111100000011100000000\n",
      "0000001111000000111100000000\n",
      "0000001111000000111100000000\n",
      "0000001111100011111100000000\n",
      "0000001111111111111100000000\n",
      "0000000111111111111100000000\n",
      "0000000011111111111100000000\n",
      "0000000000000000111100000000\n",
      "0000000000000000111100000000\n",
      "0000000000000000111000000000\n",
      "0000000000000000111000000000\n",
      "0000000000000000111000000000\n",
      "0000000000000000111000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 6:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000111100000000000\n",
      "0000000000001111110000000000\n",
      "0000000000001111100000000000\n",
      "0000000000011111000000000000\n",
      "0000000000011100000000000000\n",
      "0000000000011000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000111100000000\n",
      "0000000000100001111100000000\n",
      "0000000001111111111100000000\n",
      "0000000011111111111110000000\n",
      "0000000011111111111110000000\n",
      "0000000011111111111110000000\n",
      "0000000011111111111110000000\n",
      "0000000011111111111110000000\n",
      "0000000011111111111100000000\n",
      "0000000001111111100000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 7:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000001111111110000000\n",
      "0000000000111111111111000000\n",
      "0000000001111111111111000000\n",
      "0000000001111100011110000000\n",
      "0000000001111000011110000000\n",
      "0000000011110000111110000000\n",
      "0000000001100001111100000000\n",
      "0000000001100011111100000000\n",
      "0000000000000111111000000000\n",
      "0000000000000111110000000000\n",
      "0000000000000111110000000000\n",
      "0000000000000111100000000000\n",
      "0000000000001111000000000000\n",
      "0000000000011111000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000111110000000000000\n",
      "0000000000111100000000000000\n",
      "0000000000111000000000000000\n",
      "0000000000110000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 8:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000001111111111100000000\n",
      "0000000011111111111100000000\n",
      "0000001111111111111110000000\n",
      "0000001111111111111110000000\n",
      "0000001111100000011110000000\n",
      "0000011111100111001111000000\n",
      "0000011111101111111111110000\n",
      "0000011111111111111111110000\n",
      "0000011111111111111111111000\n",
      "0000001111111111111101111000\n",
      "0000000111111111110000111000\n",
      "0000000111110111000000111000\n",
      "0000000111000000000000111000\n",
      "0000000110000000000000111000\n",
      "0000001110000000000000111000\n",
      "0000001111000000000011110000\n",
      "0000001111100000000111100000\n",
      "0000001111111111111111100000\n",
      "0000001111111111111100000000\n",
      "0000000011111111111000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 0:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000111111100000000\n",
      "0000000000011111111110000000\n",
      "0000000000111111111111000000\n",
      "0000000001111111111111000000\n",
      "0000000001111111111111100000\n",
      "0000000011111100000111100000\n",
      "0000000111111000000111110000\n",
      "0000000111110000000011110000\n",
      "0000001111100000000011110000\n",
      "0000001111000000000011110000\n",
      "0000001111000000000111100000\n",
      "0000011111000000000111100000\n",
      "0000011110000000001111100000\n",
      "0000011111000000011111000000\n",
      "0000001111000000111110000000\n",
      "0000001111111111111110000000\n",
      "0000001111111111111100000000\n",
      "0000000111111111110000000000\n",
      "0000000001111111000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 8:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000111100000000\n",
      "0000000000000111111111000000\n",
      "0000000000001111111111000000\n",
      "0000000000001111111111000000\n",
      "0000000000011111111111000000\n",
      "0000000000011110011110000000\n",
      "0000000000111110011100000000\n",
      "0000000000111111111000000000\n",
      "0000000000111111111000000000\n",
      "0000000000111111110000000000\n",
      "0000000000111111110000000000\n",
      "0000000000111111110000000000\n",
      "0000000000111111110000000000\n",
      "0000000001100011110000000000\n",
      "0000000011100111110000000000\n",
      "0000000111111111110000000000\n",
      "0000000111111111100000000000\n",
      "0000000111111111000000000000\n",
      "0000000011111100000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "class 3:\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000111111110000000000\n",
      "0000000001111111111000000000\n",
      "0000000011111111111000000000\n",
      "0000000011111001111000000000\n",
      "0000000000000000111000000000\n",
      "0000000000000001111000000000\n",
      "0000000000011111111000000000\n",
      "0000000000111111111000000000\n",
      "0000000000111111111000000000\n",
      "0000000000111111111100000000\n",
      "0000000000001111111100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011110000000\n",
      "0000000000000000001110000000\n",
      "0000000000000000011110000000\n",
      "0000000000100000111110000000\n",
      "0000000001111111111100000000\n",
      "0000000001111111111100000000\n",
      "0000000001111111110000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "plot(P, threshold=0.55)    \n",
    "# 改進與感想\n",
    "# 1. 第二多的類別也許才是最佳代表分類 \n",
    "# 2. threshold大小(0.55 => 0.65) 顯示類別的關鍵pixel\n",
    "# 3. 由2發現其實類別6是一個大群，也許可以再往下分群得到比較正確的類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c659cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
